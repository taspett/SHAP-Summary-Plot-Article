{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SHAP Summary Plot (2/2).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oX2DHZRGX8nQ",
        "VUM4VuMj4sQD"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taspett/SHAP-Summary-Plot-Article/blob/master/SHAP_Summary_Plot_(2_2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX2DHZRGX8nQ",
        "colab_type": "text"
      },
      "source": [
        "# Example: Understanding Influences of Work Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yadRhIHk19_F",
        "colab_type": "text"
      },
      "source": [
        "For illustration purposes, I've paired downed a HR database from IBM that is available at Kaggle:  https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset\n",
        "\n",
        "This is a popular database and a number of projects have been created based on it: https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset/kernels\n",
        "\n",
        "\n",
        "https://www.kaggle.com/vsdwivedi/a-detailed-study-on-employee-attrition\n",
        "https://www.kaggle.com/patelprashant/employee-attrition/activity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf9ZzMr7YTw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install shap\n",
        "import shap\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['ReducedHR.csv']))\n",
        "\n",
        "# Data prep: one hot columns\n",
        "df = pd.get_dummies(df, columns=['Department', 'MaritalStatus', 'Attrition'])\n",
        "\n",
        "# Make y and X\n",
        "y = df['PerformanceRating']\n",
        "X = df.drop(columns='PerformanceRating')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtZEIXYHy9ov",
        "colab_type": "text"
      },
      "source": [
        "Train Model\n",
        "Train the opaque model. In this case, Random Forest.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAsawfWVzsBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "#Split train and test set.\n",
        "RANDOM_STATE = 1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    stratify=y,\n",
        "                                                    random_state=RANDOM_STATE)\n",
        "\n",
        "model = RandomForestRegressor(max_depth=4, random_state=RANDOM_STATE, n_estimators=10)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "shap_values = shap.TreeExplainer(model).shap_values(X_train)\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8XAnEvw0yIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shap.summary_plot(shap_values, X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JtbBuCLsyN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shap_values1 = np.delete(shap_values, 11, 1)\n",
        "X_train1 = X_train.drop(columns = 'PercentSalaryHike')\n",
        "\n",
        "shap_values2 = np.delete(shap_values1, 12, 1)\n",
        "X_train2 = X_train1.drop(columns = 'StockOptionLevel')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP5x1pugt0he",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shap.summary_plot(shap_values2, X_train2, max_display=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jncMohR44EkS",
        "colab_type": "text"
      },
      "source": [
        "# Summary Plot code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_j6RxbZ4Ae5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as pl\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load my colors\n",
        "# change this to load from your local machine \n",
        "# or change directory to load from your local machine\n",
        "!pip install import-ipynb\n",
        "import import_ipynb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/Colab Notebooks/Test_Rewrite_Sum'\n",
        "import colors\n",
        "\n",
        "# Original code of Summary Plot from https://github.com/slundberg/shap \n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "from scipy.stats import gaussian_kde\n",
        "try:\n",
        "    import matplotlib.pyplot as pl\n",
        "except ImportError:\n",
        "    warnings.warn(\"matplotlib could not be loaded!\")\n",
        "    pass\n",
        "#>  from . import labels\n",
        "# import colors\n",
        "\n",
        "labels = {'FEATURE': 'Feature %s',\n",
        " 'FEATURE_VALUE': 'Feature value',\n",
        " 'FEATURE_VALUE_HIGH': 'High',\n",
        " 'FEATURE_VALUE_LOW': 'Low',\n",
        " 'GLOBAL_VALUE': 'mean(|SHAP value|) (average impact on model output magnitude)',\n",
        " 'INTERACTION_EFFECT': 'SHAP interaction value for\\n%s and %s',\n",
        " 'INTERACTION_VALUE': 'SHAP interaction value',\n",
        " 'JOINT_VALUE': 'Joint SHAP value',\n",
        " 'MAIN_EFFECT': 'SHAP main effect value for\\n%s',\n",
        " 'MODEL_OUTPUT': 'Model output value',\n",
        " 'PLOT_FOR': 'SHAP plot for %s',\n",
        " 'VALUE': 'SHAP value (impact on model output)',\n",
        " 'VALUE_FOR': 'SHAP value for\\n%s'}\n",
        " \n",
        " \n",
        "# TODO: remove unused title argument / use title argument\n",
        "def my_summary_plot(shap_values, features=None, feature_names=None, max_display=None, plot_type=None,\n",
        "                 color=None, axis_color=\"#333333\", title=None, alpha=1, show=True, sort=True,\n",
        "                 color_bar=True, plot_size=\"auto\", layered_violin_max_num_bins=20, class_names=None,\n",
        "                 color_bar_label=labels[\"FEATURE_VALUE\"],\n",
        "                 # depreciated\n",
        "                 auto_size_plot=None):\n",
        "\n",
        "#>-----\n",
        "\n",
        "    # deprication warnings\n",
        "    if auto_size_plot is not None:\n",
        "        warnings.warn(\"auto_size_plot=False is depricated and is now ignored! Use plot_size=None instead.\")\n",
        "\n",
        "    multi_class = False\n",
        "    if isinstance(shap_values, list):\n",
        "        multi_class = True\n",
        "        if plot_type is None:\n",
        "            plot_type = \"bar\" # default for multi-output explanations\n",
        "        assert plot_type == \"bar\", \"Only plot_type = 'bar' is supported for multi-output explanations!\"\n",
        "    else:\n",
        "        if plot_type is None:\n",
        "            plot_type = \"dot\" # default for single output explanations\n",
        "        assert len(shap_values.shape) != 1, \"Summary plots need a matrix of shap_values, not a vector.\"\n",
        "\n",
        "    # default color:\n",
        "    if color is None:\n",
        "        if plot_type == 'layered_violin':\n",
        "            color = \"coolwarm\"\n",
        "        elif multi_class:\n",
        "            color = lambda i: colors.red_blue_circle(i/len(shap_values))\n",
        "        else:\n",
        "            color = colors.blue_rgb\n",
        "#>----------------------------------------\n",
        "#> hard coded in\n",
        "#> it doesn't do anything if color is not none\n",
        "#>----------------------------------------\n",
        "\n",
        "    # convert from a DataFrame or other types\n",
        "    if str(type(features)) == \"<class 'pandas.core.frame.DataFrame'>\":\n",
        "        if feature_names is None:\n",
        "            feature_names = features.columns\n",
        "        features = features.values\n",
        "    elif isinstance(features, list):\n",
        "        if feature_names is None:\n",
        "            feature_names = features\n",
        "        features = None\n",
        "    elif (features is not None) and len(features.shape) == 1 and feature_names is None:\n",
        "        feature_names = features\n",
        "        features = None\n",
        "\n",
        "    num_features = (shap_values[0].shape[1] if multi_class else shap_values.shape[1])\n",
        "\n",
        "    if features is not None:\n",
        "        shape_msg = \"The shape of the shap_values matrix does not match the shape of the \" \\\n",
        "                    \"provided data matrix.\"\n",
        "        if num_features - 1 == features.shape[1]:\n",
        "            assert False, shape_msg + \" Perhaps the extra column in the shap_values matrix is the \" \\\n",
        "                          \"constant offset? Of so just pass shap_values[:,:-1].\"\n",
        "        else:\n",
        "            assert num_features == features.shape[1], shape_msg\n",
        "\n",
        "    if feature_names is None:\n",
        "       feature_names = np.array([labels['FEATURE'] % str(i) for i in range(num_features)])\n",
        "\n",
        "    # plotting SHAP interaction values\n",
        "    if not multi_class and len(shap_values.shape) == 3:\n",
        "\n",
        "        if plot_type == \"compact_dot\":\n",
        "            new_shap_values = shap_values.reshape(shap_values.shape[0], -1)\n",
        "            new_features = np.tile(features, (1, 1, features.shape[1])).reshape(features.shape[0], -1)\n",
        "\n",
        "            new_feature_names = []\n",
        "            for c1 in feature_names:\n",
        "                for c2 in feature_names:\n",
        "                    if c1 == c2:\n",
        "                        new_feature_names.append(c1)\n",
        "                    else:\n",
        "                        new_feature_names.append(c1 + \"* - \" + c2)\n",
        "\n",
        "            return summary_plot(\n",
        "                new_shap_values, new_features, new_feature_names,\n",
        "                max_display=max_display, plot_type=\"dot\", color=color, axis_color=axis_color,\n",
        "                title=title, alpha=alpha, show=show, sort=sort,\n",
        "                color_bar=color_bar, plot_size=plot_size, class_names=class_names,\n",
        "                color_bar_label=\"*\" + color_bar_label\n",
        "            )\n",
        "\n",
        "        if max_display is None:\n",
        "            max_display = 7\n",
        "        else:\n",
        "            max_display = min(len(feature_names), max_display)\n",
        "\n",
        "        sort_inds = np.argsort(-np.abs(shap_values.sum(1)).sum(0))\n",
        "\n",
        "        # get plotting limits\n",
        "        delta = 1.0 / (shap_values.shape[1] ** 2)\n",
        "        slow = np.nanpercentile(shap_values, delta)\n",
        "        shigh = np.nanpercentile(shap_values, 100 - delta)\n",
        "        v = max(abs(slow), abs(shigh))\n",
        "        slow = -v\n",
        "        shigh = v\n",
        "\n",
        "        pl.figure(figsize=(1.5 * max_display + 1, 0.8 * max_display + 1))\n",
        "        pl.subplot(1, max_display, 1)\n",
        "        proj_shap_values = shap_values[:, sort_inds[0], sort_inds]\n",
        "        proj_shap_values[:, 1:] *= 2  # because off diag effects are split in half\n",
        "        summary_plot(\n",
        "            proj_shap_values, features[:, sort_inds] if features is not None else None,\n",
        "            feature_names=feature_names[sort_inds],\n",
        "            sort=False, show=False, color_bar=False,\n",
        "            plot_size=None,\n",
        "            max_display=max_display\n",
        "        )\n",
        "        pl.xlim((slow, shigh))\n",
        "        pl.xlabel(\"\")\n",
        "        title_length_limit = 11\n",
        "        pl.title(shorten_text(feature_names[sort_inds[0]], title_length_limit))\n",
        "        for i in range(1, min(len(sort_inds), max_display)):\n",
        "            ind = sort_inds[i]\n",
        "            pl.subplot(1, max_display, i + 1)\n",
        "            proj_shap_values = shap_values[:, ind, sort_inds]\n",
        "            proj_shap_values *= 2\n",
        "            proj_shap_values[:, i] /= 2  # because only off diag effects are split in half\n",
        "            summary_plot(\n",
        "                proj_shap_values, features[:, sort_inds] if features is not None else None,\n",
        "                sort=False,\n",
        "                feature_names=[\"\" for i in range(len(feature_names))],\n",
        "                show=False,\n",
        "                color_bar=False,\n",
        "                plot_size=None,\n",
        "                max_display=max_display\n",
        "            )\n",
        "            pl.xlim((slow, shigh))\n",
        "            pl.xlabel(\"\")\n",
        "            if i == min(len(sort_inds), max_display) // 2:\n",
        "                pl.xlabel(labels['INTERACTION_VALUE'])\n",
        "            pl.title(shorten_text(feature_names[ind], title_length_limit))\n",
        "        pl.tight_layout(pad=0, w_pad=0, h_pad=0.0)\n",
        "        pl.subplots_adjust(hspace=0, wspace=0.1)\n",
        "        if show:\n",
        "            pl.show()\n",
        "        return\n",
        "\n",
        "    if max_display is None:\n",
        "        max_display = 20\n",
        "\n",
        "    if sort:\n",
        "        # order features by the sum of their effect magnitudes\n",
        "        if multi_class:\n",
        "            feature_order = np.argsort(np.sum(np.mean(np.abs(shap_values), axis=0), axis=0))\n",
        "        else:\n",
        "            feature_order = np.argsort(np.sum(np.abs(shap_values), axis=0))\n",
        "        feature_order = feature_order[-min(max_display, len(feature_order)):]\n",
        "    else:\n",
        "        feature_order = np.flip(np.arange(min(max_display, num_features)), 0)\n",
        "\n",
        "    row_height = 0.4\n",
        "    if plot_size == \"auto\":\n",
        "        pl.gcf().set_size_inches(8, len(feature_order) * row_height + 1.5)\n",
        "    elif type(plot_size) in (list, tuple):\n",
        "        pl.gcf().set_size_inches(plot_size[0], plot_size[1])\n",
        "    elif plot_size is not None:\n",
        "        pl.gcf().set_size_inches(8, len(feature_order) * plot_size + 1.5)\n",
        "    pl.axvline(x=0, color=\"#999999\", zorder=-1)\n",
        "\n",
        "    if plot_type == \"dot\":\n",
        "        for pos, i in enumerate(feature_order):\n",
        "            pl.axhline(y=pos, color=\"#cccccc\", lw=0.5, dashes=(1, 5), zorder=-1)\n",
        "            shaps = shap_values[:, i]\n",
        "            values = None if features is None else features[:, i]\n",
        "            inds = np.arange(len(shaps))\n",
        "            np.random.shuffle(inds)\n",
        "            if values is not None:\n",
        "                values = values[inds]\n",
        "            shaps = shaps[inds]\n",
        "            colored_feature = True\n",
        "            try:\n",
        "                values = np.array(values, dtype=np.float64)  # make sure this can be numeric\n",
        "            except:\n",
        "                colored_feature = False\n",
        "            N = len(shaps)\n",
        "            # hspacing = (np.max(shaps) - np.min(shaps)) / 200\n",
        "            # curr_bin = []\n",
        "            nbins = 100\n",
        "            quant = np.round(nbins * (shaps - np.min(shaps)) / (np.max(shaps) - np.min(shaps) + 1e-8))\n",
        "            inds = np.argsort(quant + np.random.randn(N) * 1e-6)\n",
        "            layer = 0\n",
        "            last_bin = -1\n",
        "            ys = np.zeros(N)\n",
        "            for ind in inds:\n",
        "                if quant[ind] != last_bin:\n",
        "                    layer = 0\n",
        "                ys[ind] = np.ceil(layer / 2) * ((layer % 2) * 2 - 1)\n",
        "                layer += 1\n",
        "                last_bin = quant[ind]\n",
        "            ys *= 0.9 * (row_height / np.max(ys + 1))\n",
        "\n",
        "            if features is not None and colored_feature:\n",
        "                # trim the color range, but prevent the color range from collapsing\n",
        "                vmin = np.nanpercentile(values, 5)\n",
        "                vmax = np.nanpercentile(values, 95)\n",
        "                if vmin == vmax:\n",
        "                    vmin = np.nanpercentile(values, 1)\n",
        "                    vmax = np.nanpercentile(values, 99)\n",
        "                    if vmin == vmax:\n",
        "                        vmin = np.min(values)\n",
        "                        vmax = np.max(values)\n",
        "\n",
        "                assert features.shape[0] == len(shaps), \"Feature and SHAP matrices must have the same number of rows!\"\n",
        "\n",
        "                # plot the nan values in the interaction feature as grey\n",
        "                nan_mask = np.isnan(values)\n",
        "                pl.scatter(shaps[nan_mask], pos + ys[nan_mask], color=\"#777777\", vmin=vmin,\n",
        "                           vmax=vmax, s=16, alpha=alpha, linewidth=0,\n",
        "                           zorder=3, rasterized=len(shaps) > 500)\n",
        "\n",
        "                # plot the non-nan values colored by the trimmed feature value\n",
        "                cvals = values[np.invert(nan_mask)].astype(np.float64)\n",
        "                cvals_imp = cvals.copy()\n",
        "                cvals_imp[np.isnan(cvals)] = (vmin + vmax) / 2.0\n",
        "                cvals[cvals_imp > vmax] = vmax\n",
        "                cvals[cvals_imp < vmin] = vmin\n",
        "                pl.scatter(shaps[np.invert(nan_mask)], pos + ys[np.invert(nan_mask)],\n",
        "                           cmap=colors.red_blue, vmin=vmin, vmax=vmax, s=16,\n",
        "                           c=cvals, alpha=alpha, linewidth=0,\n",
        "                           zorder=3, rasterized=len(shaps) > 500)\n",
        "\n",
        "            else:\n",
        "\n",
        "                pl.scatter(shaps, pos + ys, s=16, alpha=alpha, linewidth=0, zorder=3,\n",
        "                           color=color if colored_feature else \"#777777\", rasterized=len(shaps) > 500)\n",
        "\n",
        "    elif plot_type == \"violin\":\n",
        "        for pos, i in enumerate(feature_order):\n",
        "            pl.axhline(y=pos, color=\"#cccccc\", lw=0.5, dashes=(1, 5), zorder=-1)\n",
        "\n",
        "        if features is not None:\n",
        "            global_low = np.nanpercentile(shap_values[:, :len(feature_names)].flatten(), 1)\n",
        "            global_high = np.nanpercentile(shap_values[:, :len(feature_names)].flatten(), 99)\n",
        "            for pos, i in enumerate(feature_order):\n",
        "                shaps = shap_values[:, i]\n",
        "                shap_min, shap_max = np.min(shaps), np.max(shaps)\n",
        "                rng = shap_max - shap_min\n",
        "                xs = np.linspace(np.min(shaps) - rng * 0.2, np.max(shaps) + rng * 0.2, 100)\n",
        "                if np.std(shaps) < (global_high - global_low) / 100:\n",
        "                    ds = gaussian_kde(shaps + np.random.randn(len(shaps)) * (global_high - global_low) / 100)(xs)\n",
        "                else:\n",
        "                    ds = gaussian_kde(shaps)(xs)\n",
        "                ds /= np.max(ds) * 3\n",
        "\n",
        "                values = features[:, i]\n",
        "                window_size = max(10, len(values) // 20)\n",
        "                smooth_values = np.zeros(len(xs) - 1)\n",
        "                sort_inds = np.argsort(shaps)\n",
        "                trailing_pos = 0\n",
        "                leading_pos = 0\n",
        "                running_sum = 0\n",
        "                back_fill = 0\n",
        "                for j in range(len(xs) - 1):\n",
        "\n",
        "                    while leading_pos < len(shaps) and xs[j] >= shaps[sort_inds[leading_pos]]:\n",
        "                        running_sum += values[sort_inds[leading_pos]]\n",
        "                        leading_pos += 1\n",
        "                        if leading_pos - trailing_pos > 20:\n",
        "                            running_sum -= values[sort_inds[trailing_pos]]\n",
        "                            trailing_pos += 1\n",
        "                    if leading_pos - trailing_pos > 0:\n",
        "                        smooth_values[j] = running_sum / (leading_pos - trailing_pos)\n",
        "                        for k in range(back_fill):\n",
        "                            smooth_values[j - k - 1] = smooth_values[j]\n",
        "                    else:\n",
        "                        back_fill += 1\n",
        "\n",
        "                vmin = np.nanpercentile(values, 5)\n",
        "                vmax = np.nanpercentile(values, 95)\n",
        "                if vmin == vmax:\n",
        "                    vmin = np.nanpercentile(values, 1)\n",
        "                    vmax = np.nanpercentile(values, 99)\n",
        "                    if vmin == vmax:\n",
        "                        vmin = np.min(values)\n",
        "                        vmax = np.max(values)\n",
        "                pl.scatter(shaps, np.ones(shap_values.shape[0]) * pos, s=9, cmap=colors.red_blue, vmin=vmin, vmax=vmax,\n",
        "                           c=values, alpha=alpha, linewidth=0, zorder=1)\n",
        "                # smooth_values -= nxp.nanpercentile(smooth_values, 5)\n",
        "                # smooth_values /= np.nanpercentile(smooth_values, 95)\n",
        "                smooth_values -= vmin\n",
        "                if vmax - vmin > 0:\n",
        "                    smooth_values /= vmax - vmin\n",
        "                for i in range(len(xs) - 1):\n",
        "                    if ds[i] > 0.05 or ds[i + 1] > 0.05:\n",
        "                        pl.fill_between([xs[i], xs[i + 1]], [pos + ds[i], pos + ds[i + 1]],\n",
        "                                        [pos - ds[i], pos - ds[i + 1]], color=colors.red_blue(smooth_values[i]),\n",
        "                                        zorder=2)\n",
        "\n",
        "        else:\n",
        "            parts = pl.violinplot(shap_values[:, feature_order], range(len(feature_order)), points=200, vert=False,\n",
        "                                  widths=0.7,\n",
        "                                  showmeans=False, showextrema=False, showmedians=False)\n",
        "\n",
        "            for pc in parts['bodies']:\n",
        "                pc.set_facecolor(color)\n",
        "                pc.set_edgecolor('none')\n",
        "                pc.set_alpha(alpha)\n",
        "\n",
        "    elif plot_type == \"layered_violin\":  # courtesy of @kodonnell\n",
        "        num_x_points = 200\n",
        "        bins = np.linspace(0, features.shape[0], layered_violin_max_num_bins + 1).round(0).astype(\n",
        "            'int')  # the indices of the feature data corresponding to each bin\n",
        "        shap_min, shap_max = np.min(shap_values), np.max(shap_values)\n",
        "        x_points = np.linspace(shap_min, shap_max, num_x_points)\n",
        "\n",
        "        # loop through each feature and plot:\n",
        "        for pos, ind in enumerate(feature_order):\n",
        "            # decide how to handle: if #unique < layered_violin_max_num_bins then split by unique value, otherwise use bins/percentiles.\n",
        "            # to keep simpler code, in the case of uniques, we just adjust the bins to align with the unique counts.\n",
        "            feature = features[:, ind]\n",
        "            unique, counts = np.unique(feature, return_counts=True)\n",
        "            if unique.shape[0] <= layered_violin_max_num_bins:\n",
        "                order = np.argsort(unique)\n",
        "                thesebins = np.cumsum(counts[order])\n",
        "                thesebins = np.insert(thesebins, 0, 0)\n",
        "            else:\n",
        "                thesebins = bins\n",
        "            nbins = thesebins.shape[0] - 1\n",
        "            # order the feature data so we can apply percentiling\n",
        "            order = np.argsort(feature)\n",
        "            # x axis is located at y0 = pos, with pos being there for offset\n",
        "            y0 = np.ones(num_x_points) * pos\n",
        "            # calculate kdes:\n",
        "            ys = np.zeros((nbins, num_x_points))\n",
        "            for i in range(nbins):\n",
        "                # get shap values in this bin:\n",
        "                shaps = shap_values[order[thesebins[i]:thesebins[i + 1]], ind]\n",
        "                # if there's only one element, then we can't\n",
        "                if shaps.shape[0] == 1:\n",
        "                    warnings.warn(\n",
        "                        \"not enough data in bin #%d for feature %s, so it'll be ignored. Try increasing the number of records to plot.\"\n",
        "                        % (i, feature_names[ind]))\n",
        "                    # to ignore it, just set it to the previous y-values (so the area between them will be zero). Not ys is already 0, so there's\n",
        "                    # nothing to do if i == 0\n",
        "                    if i > 0:\n",
        "                        ys[i, :] = ys[i - 1, :]\n",
        "                    continue\n",
        "                # save kde of them: note that we add a tiny bit of gaussian noise to avoid singular matrix errors\n",
        "                ys[i, :] = gaussian_kde(shaps + np.random.normal(loc=0, scale=0.001, size=shaps.shape[0]))(x_points)\n",
        "                # scale it up so that the 'size' of each y represents the size of the bin. For continuous data this will\n",
        "                # do nothing, but when we've gone with the unqique option, this will matter - e.g. if 99% are male and 1%\n",
        "                # female, we want the 1% to appear a lot smaller.\n",
        "                size = thesebins[i + 1] - thesebins[i]\n",
        "                bin_size_if_even = features.shape[0] / nbins\n",
        "                relative_bin_size = size / bin_size_if_even\n",
        "                ys[i, :] *= relative_bin_size\n",
        "            # now plot 'em. We don't plot the individual strips, as this can leave whitespace between them.\n",
        "            # instead, we plot the full kde, then remove outer strip and plot over it, etc., to ensure no\n",
        "            # whitespace\n",
        "            ys = np.cumsum(ys, axis=0)\n",
        "            width = 0.8\n",
        "            scale = ys.max() * 2 / width  # 2 is here as we plot both sides of x axis\n",
        "            for i in range(nbins - 1, -1, -1):\n",
        "                y = ys[i, :] / scale\n",
        "                c = pl.get_cmap(color)(i / (\n",
        "                        nbins - 1)) if color in pl.cm.datad else color  # if color is a cmap, use it, otherwise use a color\n",
        "                pl.fill_between(x_points, pos - y, pos + y, facecolor=c)\n",
        "        pl.xlim(shap_min, shap_max)\n",
        "\n",
        "    elif not multi_class and plot_type == \"bar\":\n",
        "        feature_inds = feature_order[:max_display]\n",
        "        y_pos = np.arange(len(feature_inds))\n",
        "        global_shap_values = np.abs(shap_values).mean(0)\n",
        "        pl.barh(y_pos, global_shap_values[feature_inds], 0.7, align='center', color=color)\n",
        "        pl.yticks(y_pos, fontsize=13)\n",
        "        pl.gca().set_yticklabels([feature_names[i] for i in feature_inds])\n",
        "\n",
        "    elif multi_class and plot_type == \"bar\":\n",
        "        if class_names is None:\n",
        "            class_names = [\"Class \"+str(i) for i in range(len(shap_values))]\n",
        "        feature_inds = feature_order[:max_display]\n",
        "        y_pos = np.arange(len(feature_inds))\n",
        "        left_pos = np.zeros(len(feature_inds))\n",
        "\n",
        "        class_inds = np.argsort([-np.abs(shap_values[i]).mean() for i in range(len(shap_values))])\n",
        "        for i,ind in enumerate(class_inds):\n",
        "            global_shap_values = np.abs(shap_values[ind]).mean(0)\n",
        "            pl.barh(\n",
        "                y_pos, global_shap_values[feature_inds], 0.7, left=left_pos, align='center',\n",
        "                color=color(i), label=class_names[ind]\n",
        "            )\n",
        "            left_pos += global_shap_values[feature_inds]\n",
        "        pl.yticks(y_pos, fontsize=13)\n",
        "        pl.gca().set_yticklabels([feature_names[i] for i in feature_inds])\n",
        "        pl.legend(frameon=False, fontsize=12)\n",
        "\n",
        "    # draw the color bar\n",
        "    if color_bar and features is not None and plot_type != \"bar\" and \\\n",
        "            (plot_type != \"layered_violin\" or color in pl.cm.datad):\n",
        "        import matplotlib.cm as cm\n",
        "        m = cm.ScalarMappable(cmap=colors.red_blue if plot_type != \"layered_violin\" else pl.get_cmap(color))\n",
        "        m.set_array([0, 1])\n",
        "        cb = pl.colorbar(m, ticks=[0, 1], aspect=1000)\n",
        "        cb.set_ticklabels([labels['FEATURE_VALUE_LOW'], labels['FEATURE_VALUE_HIGH']])\n",
        "        cb.set_label(color_bar_label, size=12, labelpad=0)\n",
        "        cb.ax.tick_params(labelsize=11, length=0)\n",
        "        cb.set_alpha(1)\n",
        "        cb.outline.set_visible(False)\n",
        "        bbox = cb.ax.get_window_extent().transformed(pl.gcf().dpi_scale_trans.inverted())\n",
        "        cb.ax.set_aspect((bbox.height - 0.9) * 20)\n",
        "        # cb.draw_all()\n",
        "\n",
        "    pl.gca().xaxis.set_ticks_position('bottom')\n",
        "    pl.gca().yaxis.set_ticks_position('none')\n",
        "    pl.gca().spines['right'].set_visible(False)\n",
        "    pl.gca().spines['top'].set_visible(False)\n",
        "    pl.gca().spines['left'].set_visible(False)\n",
        "    pl.gca().tick_params(color=axis_color, labelcolor=axis_color)\n",
        "    pl.yticks(range(len(feature_order)), [feature_names[i] for i in feature_order], fontsize=13)\n",
        "    if plot_type != \"bar\":\n",
        "        pl.gca().tick_params('y', length=20, width=0.5, which='major')\n",
        "    pl.gca().tick_params('x', labelsize=11)\n",
        "    pl.ylim(-1, len(feature_order))\n",
        "    if plot_type == \"bar\":\n",
        "      pl.xlabel(labels['GLOBAL_VALUE'], fontsize=13)\n",
        "    else:\n",
        "      pl.xlabel(labels['VALUE'], fontsize=13)\n",
        "    if show:\n",
        "        pl.show()\n",
        "\n",
        "\n",
        "def shorten_text(text, length_limit):\n",
        "    if len(text) > length_limit:\n",
        "        return text[:length_limit - 3] + \"...\"\n",
        "    else:\n",
        "        return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUM4VuMj4sQD",
        "colab_type": "text"
      },
      "source": [
        "# New Summary Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3NVQrMW-zng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_summary_plot(shap_values, X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtprMYCGYFx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_summary_plot(shap_values, X_train, max_display=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srtriHvX5PNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_summary_plot(shap_values2, X_train2, max_display=3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}